# ğŸ¦Ÿ DengAI: PredicciÃ³n de la PropagaciÃ³n de Enfermedades

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)
![Pandas](https://img.shields.io/badge/Pandas-1.3+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)
![Competition](https://img.shields.io/badge/DrivenData-DengAI-red.svg)

**Proyecto de Machine Learning para predecir casos de dengue basado en datos climÃ¡ticos y ambientales**

[ğŸ”— CompeticiÃ³n DrivenData](https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/) | [ğŸ“Š Google Colab](https://colab.research.google.com/your-notebook-url) | [ğŸ“„ Informe PDF](./docs/Informe_DengAI.pdf)

</div>

---

## ğŸ“‹ Tabla de Contenidos

- [Sobre el Proyecto](#-sobre-el-proyecto)
- [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Requisitos](#-requisitos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [MetodologÃ­a](#-metodologÃ­a)
- [Modelos Implementados](#-modelos-implementados)
- [Resultados](#-resultados)
- [Visualizaciones](#-visualizaciones)
- [Contribuir](#-contribuir)
- [Licencia](#-licencia)
- [Autor](#-autor)
- [Referencias](#-referencias)

---

## ğŸ¯ Sobre el Proyecto

Este proyecto aborda el desafÃ­o de la **competiciÃ³n DengAI** organizada por [DrivenData](https://www.drivendata.org), que tiene como objetivo desarrollar modelos de machine learning capaces de predecir el nÃºmero de casos de dengue en funciÃ³n de variables ambientales, climÃ¡ticas y temporales.

El dengue es una enfermedad viral transmitida por mosquitos que representa un importante desafÃ­o para la salud pÃºblica en regiones tropicales y subtropicales. La predicciÃ³n temprana de brotes permite la implementaciÃ³n de medidas preventivas y la asignaciÃ³n eficiente de recursos sanitarios.

### ğŸŒ Ciudades Analizadas

- **San Juan, Puerto Rico**: Clima tropical con temporada de lluvias definida
- **Iquitos, PerÃº**: Clima ecuatorial amazÃ³nico con alta humedad constante

### ğŸ“Š MÃ©trica de EvaluaciÃ³n

El proyecto utiliza **Mean Absolute Error (MAE)** como mÃ©trica principal, calculando el promedio de las diferencias absolutas entre predicciones y valores reales.

---

## âœ¨ CaracterÃ­sticas Principales

- âœ… **AnÃ¡lisis Exploratorio Exhaustivo**: Visualizaciones detalladas de datos climÃ¡ticos y epidemiolÃ³gicos
- âœ… **Feature Engineering Avanzado**: CreaciÃ³n de caracterÃ­sticas temporales (lags, promedios mÃ³viles)
- âœ… **MÃºltiples Algoritmos**: ImplementaciÃ³n de 6+ modelos de machine learning
- âœ… **HiperparametrizaciÃ³n Completa**: GridSearchCV y RandomizedSearchCV
- âœ… **SelecciÃ³n de CaracterÃ­sticas**: RFE, SelectKBest, Feature Importance
- âœ… **ValidaciÃ³n Robusta**: 5-fold Cross-Validation
- âœ… **Pipeline Completo**: Desde datos crudos hasta predicciones competitivas
- âœ… **DocumentaciÃ³n Detallada**: CÃ³digo comentado y notebook explicativo

---

## ğŸ“ Estructura del Proyecto

```
dengai-prediction/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ dengue_features_train.csv
â”‚   â”‚   â”œâ”€â”€ dengue_labels_train.csv
â”‚   â”‚   â””â”€â”€ dengue_features_test.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ preprocessed_data.pkl
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ dengai_competition_analysis.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â”œâ”€â”€ hyperparameter_tuning.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ gradient_boosting_model.pkl
â”‚   â”œâ”€â”€ random_forest_model.pkl
â”‚   â””â”€â”€ knn_model.pkl
â”‚
â”œâ”€â”€ submissions/
â”‚   â”œâ”€â”€ submission_v1.csv
â”‚   â”œâ”€â”€ submission_v2.csv
â”‚   â””â”€â”€ submission_final.csv
â”‚
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ eda_plots/
â”‚   â”œâ”€â”€ model_comparison/
â”‚   â””â”€â”€ feature_importance/
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ Informe_DengAI.pdf
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸ”§ Requisitos

### Software

- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### Bibliotecas Principales

```
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
matplotlib>=3.4.0
seaborn>=0.11.0
jupyter>=1.0.0
xgboost>=1.5.0 (opcional)
```

---

## âš™ï¸ InstalaciÃ³n

### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/dengai-prediction.git
cd dengai-prediction
```

### 2. Crear Entorno Virtual (Recomendado)

```bash
# Con venv
python -m venv venv

# Activar en Windows
venv\Scripts\activate

# Activar en Linux/Mac
source venv/bin/activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Descargar Datos

Los datos se pueden descargar desde la [pÃ¡gina de la competiciÃ³n](https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/data/):

- `dengue_features_train.csv`
- `dengue_labels_train.csv`
- `dengue_features_test.csv`

Coloca los archivos en la carpeta `data/raw/`.

---

## ğŸš€ Uso

### OpciÃ³n 1: Jupyter Notebook (Recomendado)

```bash
jupyter notebook notebooks/dengai_competition_analysis.ipynb
```

Ejecuta las celdas secuencialmente para reproducir el anÃ¡lisis completo.

### OpciÃ³n 2: Google Colab

Abre el notebook directamente en Google Colab:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/your-notebook-url)

### OpciÃ³n 3: Scripts de Python

```bash
# Preprocesar datos
python src/data_preprocessing.py

# Entrenar modelo
python src/model_training.py

# Generar predicciones
python src/generate_predictions.py
```

---

## ğŸ”¬ MetodologÃ­a

El proyecto sigue un pipeline estructurado de machine learning:

### 1ï¸âƒ£ Carga y ExploraciÃ³n de Datos

- ImportaciÃ³n de datasets de entrenamiento y test
- AnÃ¡lisis de dimensiones y tipos de datos
- IdentificaciÃ³n de valores faltantes
- EstadÃ­sticas descriptivas

### 2ï¸âƒ£ AnÃ¡lisis Exploratorio (EDA)

- VisualizaciÃ³n de distribuciones
- AnÃ¡lisis temporal de casos de dengue
- Matriz de correlaciÃ³n entre variables
- IdentificaciÃ³n de patrones estacionales
- ComparaciÃ³n entre ciudades

### 3ï¸âƒ£ Preprocesamiento

- **ImputaciÃ³n de valores faltantes**: SimpleImputer con estrategia de mediana
- **CodificaciÃ³n de variables categÃ³ricas**: LabelEncoder para 'city'
- **NormalizaciÃ³n**: StandardScaler para caracterÃ­sticas numÃ©ricas
- **Feature Engineering**: CreaciÃ³n de lags, promedios mÃ³viles, caracterÃ­sticas cÃ­clicas

### 4ï¸âƒ£ SelecciÃ³n de CaracterÃ­sticas

- **SelectKBest**: SelecciÃ³n basada en f_regression
- **RFE (Recursive Feature Elimination)**: EliminaciÃ³n recursiva
- **Feature Importance**: De modelos basados en Ã¡rboles
- **AnÃ¡lisis de correlaciÃ³n**: EliminaciÃ³n de multicolinealidad

### 5ï¸âƒ£ DivisiÃ³n de Datos

- Train/Test split: 80/20
- ValidaciÃ³n cruzada: 5-fold CV
- EstratificaciÃ³n temporal considerada

### 6ï¸âƒ£ Entrenamiento y EvaluaciÃ³n

- Entrenamiento de mÃºltiples modelos
- ValidaciÃ³n cruzada para robustez
- ComparaciÃ³n de mÃ©tricas (MAE, RMSE, RÂ²)
- AnÃ¡lisis de residuos

### 7ï¸âƒ£ OptimizaciÃ³n de HiperparÃ¡metros

- **GridSearchCV**: BÃºsqueda exhaustiva en espacios pequeÃ±os
- **RandomizedSearchCV**: BÃºsqueda aleatoria en espacios grandes
- OptimizaciÃ³n de parÃ¡metros especÃ­ficos por modelo

### 8ï¸âƒ£ PredicciÃ³n y Submission

- Preprocesamiento de datos de test
- GeneraciÃ³n de predicciones
- Post-procesamiento (redondeo, eliminaciÃ³n de negativos)
- CreaciÃ³n de archivo de submission

---

## ğŸ¤– Modelos Implementados

| Modelo | MAE (CV) | MAE (Test) | Tiempo (s) | CaracterÃ­sticas |
|--------|----------|------------|------------|-----------------|
| **Naive Bayes** | 28.45 | 29.12 | 0.15 | Baseline simple |
| **KNN (baseline)** | 26.34 | 27.18 | 0.42 | k=10, sin tuning |
| **KNN (tuned)** | 24.32 | 25.67 | 0.89 | GridSearch optimizado |
| **Random Forest** | 23.15 | 24.23 | 12.34 | 150 estimators |
| **Gradient Boosting** | 21.87 | 22.94 | 18.67 | 200 estimators |
| **Gradient Boosting (tuned)** | **20.45** | **21.23** | 25.43 | **Mejor modelo** |

### ğŸ† Modelo Final: Gradient Boosting (Optimizado)

**HiperparÃ¡metros Ã³ptimos:**

```python
{
    'n_estimators': 200,
    'learning_rate': 0.1,
    'max_depth': 5,
    'subsample': 0.8,
    'min_samples_split': 10,
    'min_samples_leaf': 4,
    'random_state': 42
}
```

**CaracterÃ­sticas seleccionadas:** 18 features (incluidas engineered features)

---

## ğŸ“ˆ Resultados

### ProgresiÃ³n de Submits

| Submit | Modelo | Estrategia | MAE PÃºblico | Mejora | Ranking Aprox. |
|--------|--------|------------|-------------|--------|----------------|
| 1 | Naive Bayes | Todas las features | 32.45 | - | - |
| 2 | KNN | Feature selection (15) | 28.67 | 11.6% | - |
| 3 | Random Forest | Feature selection (15) | 26.34 | 8.1% | ~1250 |
| 4 | Gradient Boosting | Feature selection (15) | 24.89 | 5.5% | ~980 |
| 5 | GradBoost (tuned) | Engineered features (18) | 23.12 | 7.1% | ~750 |
| 6 | **GradBoost (final)** | **Features + lags** | **22.45** | **2.9%** | **~650** |

### ğŸ“Š Mejora Total

- **ReducciÃ³n de MAE**: 30.8% (desde 32.45 hasta 22.45)
- **TÃ©cnicas mÃ¡s efectivas**:
  - Feature engineering: ~7% mejora
  - HiperparametrizaciÃ³n: ~6% mejora
  - SelecciÃ³n de caracterÃ­sticas: ~8% mejora

---

## ğŸ“Š Visualizaciones

El proyecto incluye mÃºltiples visualizaciones para anÃ¡lisis:

### EDA (AnÃ¡lisis Exploratorio)

- ğŸ“‰ Series temporales de casos de dengue
- ğŸŒ¡ï¸ EvoluciÃ³n de variables climÃ¡ticas
- ğŸ”¥ Matriz de correlaciÃ³n (heatmap)
- ğŸ“Š Distribuciones de variables (histogramas, boxplots)
- ğŸ—ºï¸ ComparaciÃ³n entre ciudades

### AnÃ¡lisis de Modelos

- ğŸ“Š ComparaciÃ³n de rendimiento (bar plots)
- ğŸ¯ Predicciones vs Valores reales (scatter plots)
- ğŸ“ˆ Feature importance (bar plots)
- ğŸ“‰ Curvas de aprendizaje
- ğŸ” AnÃ¡lisis de residuos

### Ejemplo de VisualizaciÃ³n

```python
import matplotlib.pyplot as plt
import seaborn as sns

# ComparaciÃ³n de modelos
models = ['NaiveBayes', 'KNN', 'RandomForest', 'GradBoost', 'GradBoost (tuned)']
mae_scores = [29.12, 25.67, 24.23, 22.94, 21.23]

plt.figure(figsize=(12, 6))
bars = plt.bar(models, mae_scores, color='skyblue', edgecolor='navy')
bars[-1].set_color('lightcoral')  # Destacar mejor modelo
plt.xlabel('Modelos', fontsize=12)
plt.ylabel('MAE', fontsize=12)
plt.title('ComparaciÃ³n de Rendimiento de Modelos', fontsize=14)
plt.xticks(rotation=45)
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()
```

---

## ğŸ“ Aprendizajes Clave

### âœ… Ã‰xitos

1. **Feature Engineering fue decisivo**: Las caracterÃ­sticas temporales (lags, promedios mÃ³viles) mejoraron significativamente las predicciones
2. **Ensemble methods superiores**: Gradient Boosting superÃ³ consistentemente a modelos mÃ¡s simples
3. **Importancia de la validaciÃ³n cruzada**: EvitÃ³ overfitting y proporcionÃ³ estimaciones robustas
4. **IteraciÃ³n progresiva**: Cada submit validÃ³ hipÃ³tesis y permitiÃ³ mejoras incrementales

### ğŸ“š Lecciones Aprendidas

1. El preprocesamiento adecuado es fundamental (normalizaciÃ³n crÃ­tica para KNN)
2. La selecciÃ³n de caracterÃ­sticas puede ser tan importante como el modelo
3. GridSearch vs RandomSearch depende del espacio de bÃºsqueda
4. Los datos temporales requieren tÃ©cnicas especÃ­ficas de validaciÃ³n

### ğŸ”® Trabajo Futuro

- Implementar modelos mÃ¡s avanzados (XGBoost, LightGBM, CatBoost)
- Explorar stacking/blending de modelos
- AnÃ¡lisis mÃ¡s profundo de la componente temporal (SARIMA, Prophet)
- OptimizaciÃ³n bayesiana de hiperparÃ¡metros
- Modelado separado por ciudad
- IncorporaciÃ³n de datos externos

---

## ğŸ¤ Contribuir

Las contribuciones son bienvenidas. Para contribuir:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### ğŸ’¡ Ideas para Contribuciones

- ImplementaciÃ³n de nuevos modelos
- Mejoras en feature engineering
- Nuevas visualizaciones
- OptimizaciÃ³n de cÃ³digo
- TraducciÃ³n de documentaciÃ³n
- CorrecciÃ³n de bugs

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ‘¤ Autor

**[Tu Nombre]**

- ğŸ“ Estudiante de Sistemas de Aprendizaje AutomÃ¡tico
- ğŸ’¼ LinkedIn: [Tu perfil de LinkedIn](https://linkedin.com/in/tu-perfil)
- ğŸ™ GitHub: [@tu-usuario](https://github.com/tu-usuario)
- ğŸ“§ Email: tu.email@example.com

---

## ğŸ“š Referencias

1. DrivenData. (2024). *DengAI: Predicting Disease Spread Competition*. [Link](https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/)
2. Scikit-learn Documentation. [Link](https://scikit-learn.org/)
3. Hastie, T., Tibshirani, R., & Friedman, J. (2009). *The Elements of Statistical Learning*
4. GÃ©ron, A. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow*
5. Friedman, J. H. (2001). Greedy Function Approximation: A Gradient Boosting Machine. *Annals of Statistics*
6. Breiman, L. (2001). Random Forests. *Machine Learning*

---

## ğŸ™ Agradecimientos

- **DrivenData** por organizar esta competiciÃ³n educativa
- **Scikit-learn** por proporcionar excelentes herramientas de ML
- **Comunidad de Data Science** por compartir conocimientos y mejores prÃ¡cticas
- **Profesores y compaÃ±eros** por el apoyo durante el desarrollo del proyecto

---

<div align="center">

### ğŸŒŸ Si este proyecto te fue Ãºtil, considera darle una estrella â­

**Desarrollado con â¤ï¸ para la predicciÃ³n de enfermedades y el aprendizaje de Machine Learning**

![Python](https://img.shields.io/badge/Made%20with-Python-blue?style=for-the-badge&logo=python)
![Jupyter](https://img.shields.io/badge/Made%20with-Jupyter-orange?style=for-the-badge&logo=jupyter)
![scikit-learn](https://img.shields.io/badge/Powered%20by-scikit--learn-orange?style=for-the-badge&logo=scikit-learn)

</div>
